{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ones</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age Range</th>\n",
       "      <th>Head Size(cm^3)</th>\n",
       "      <th>Brain Weight(grams)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.874879</td>\n",
       "      <td>-1.072228</td>\n",
       "      <td>2.403781</td>\n",
       "      <td>2.053562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.874879</td>\n",
       "      <td>-1.072228</td>\n",
       "      <td>0.284751</td>\n",
       "      <td>0.117388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.874879</td>\n",
       "      <td>-1.072228</td>\n",
       "      <td>1.716602</td>\n",
       "      <td>0.433159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.874879</td>\n",
       "      <td>-1.072228</td>\n",
       "      <td>0.391524</td>\n",
       "      <td>-0.007258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.874879</td>\n",
       "      <td>-1.072228</td>\n",
       "      <td>1.486630</td>\n",
       "      <td>2.552148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ones    Gender  Age Range  Head Size(cm^3)  Brain Weight(grams)\n",
       "0     1 -0.874879  -1.072228         2.403781             2.053562\n",
       "1     1 -0.874879  -1.072228         0.284751             0.117388\n",
       "2     1 -0.874879  -1.072228         1.716602             0.433159\n",
       "3     1 -0.874879  -1.072228         0.391524            -0.007258\n",
       "4     1 -0.874879  -1.072228         1.486630             2.552148"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"headbrain.csv\")\n",
    "mean = data.mean()\n",
    "std = data.std()  \n",
    "data = (data - mean) / std \n",
    "data.insert(0, 'Ones', 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(\"Brain Weight(grams)\",axis =1)\n",
    "y= data[\"Brain Weight(grams)\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "      X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self, X, y,X_valid, y_valid,  epochs = 1000, lr = 0.0001):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr        \n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.optim = GradientDesent(X, y, epochs,lr)\n",
    "        \n",
    "    def fit(self):       \n",
    "        self.w = self.optim.optimize()        \n",
    "        y_preds = np.dot(self.X,self.w)         \n",
    "        \n",
    "        score = self.RMSE(self.y,y_preds)\n",
    "        print(f'Model Score { score }')\n",
    "    \n",
    "    def RMSE(self, y_actual , y_preds):\n",
    "        return np.sqrt(np.sum((y_actual - y_preds)**2)/len(y_actual))\n",
    "        \n",
    "    def predict(self):\n",
    "        y_preds = np.dot(self.X_valid,self.w) \n",
    "        score = self.RMSE(self.y_valid,y_preds)\n",
    "        print(f'Validation Score { score }')\n",
    "        \n",
    "        \n",
    "    def predictTest(self, test, mean, std):            \n",
    "        preds =  np.dot(test,self.w)\n",
    "        denormalizePreds = (preds * std) + mean\n",
    "        print(f'N Predictions : {preds}') \n",
    "        print(f'Predictions : {denormalizePreds}')      \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDesent():\n",
    "    def __init__(self, X, y, epochs , lr):\n",
    "        self.X =X\n",
    "        self.y =y\n",
    "        self.epochs = epochs\n",
    "        self.lr =lr\n",
    "      \n",
    "         \n",
    "    def optimize(self):\n",
    "        \n",
    "        w =np.ones(X.shape[1])\n",
    "      \n",
    "        prev_loss = 9999999\n",
    "        for i in range(self.epochs):\n",
    "            gradient = self.StepGrandient(w);            \n",
    "            w = w - (gradient * self.lr)       \n",
    "            loss = self.Loss(w)\n",
    "            \n",
    "            if(loss > prev_loss):\n",
    "                 print('Early stopping since loss in increasing')  \n",
    "                 return w            \n",
    "            \n",
    "            prev_w = w\n",
    "            prev_loss = loss\n",
    "            print (f'Epoch:{i} Loss:{loss} ')\n",
    "            \n",
    "                      \n",
    "        return w\n",
    "                \n",
    "        \n",
    "    def StepGrandient(self, w):        \n",
    "        m = len(self.X)            \n",
    "        h =np.dot(self.X,w)\n",
    "        loss = h - self.y\n",
    "        grad = np.dot(self.X.T,loss)/m\n",
    "            \n",
    "        return grad \n",
    "        \n",
    "        \n",
    "    def Loss(self, w):\n",
    "        h = np.dot(self.X,w) \n",
    "        m = len(self.X)   \n",
    "        return np.sum(np.power(h - self.y,2))/(2*m)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(X_train, y_train,X_test,y_test, epochs = 1000, lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Loss:1.6002688855138287 \n",
      "Epoch:1 Loss:1.5723358114136525 \n",
      "Epoch:2 Loss:1.5450087400001347 \n",
      "Epoch:3 Loss:1.5182736328936357 \n",
      "Epoch:4 Loss:1.4921167940322706 \n",
      "Epoch:5 Loss:1.466524860947738 \n",
      "Epoch:6 Loss:1.4414847962721848 \n",
      "Epoch:7 Loss:1.416983879469782 \n",
      "Epoch:8 Loss:1.3930096987868654 \n",
      "Epoch:9 Loss:1.3695501434146806 \n",
      "Epoch:10 Loss:1.346593395858937 \n",
      "Epoch:11 Loss:1.3241279245105118 \n",
      "Epoch:12 Loss:1.302142476411853 \n",
      "Epoch:13 Loss:1.2806260702137289 \n",
      "Epoch:14 Loss:1.259567989317164 \n",
      "Epoch:15 Loss:1.238957775195512 \n",
      "Epoch:16 Loss:1.2187852208917895 \n",
      "Epoch:17 Loss:1.1990403646864989 \n",
      "Epoch:18 Loss:1.1797134839313301 \n",
      "Epoch:19 Loss:1.1607950890442333 \n",
      "Epoch:20 Loss:1.1422759176615025 \n",
      "Epoch:21 Loss:1.1241469289426205 \n",
      "Epoch:22 Loss:1.1063992980237267 \n",
      "Epoch:23 Loss:1.0890244106157125 \n",
      "Epoch:24 Loss:1.072013857743006 \n",
      "Epoch:25 Loss:1.0553594306193006 \n",
      "Epoch:26 Loss:1.039053115656484 \n",
      "Epoch:27 Loss:1.0230870896032167 \n",
      "Epoch:28 Loss:1.0074537148096707 \n",
      "Epoch:29 Loss:0.9921455346150037 \n",
      "Epoch:30 Loss:0.9771552688543114 \n",
      "Epoch:31 Loss:0.9624758094818359 \n",
      "Epoch:32 Loss:0.948100216307295 \n",
      "Epoch:33 Loss:0.9340217128423384 \n",
      "Epoch:34 Loss:0.9202336822541387 \n",
      "Epoch:35 Loss:0.9067296634232929 \n",
      "Epoch:36 Loss:0.8935033471032088 \n",
      "Epoch:37 Loss:0.8805485721782995 \n",
      "Epoch:38 Loss:0.8678593220183226 \n",
      "Epoch:39 Loss:0.8554297209263149 \n",
      "Epoch:40 Loss:0.843254030677627 \n",
      "Epoch:41 Loss:0.8313266471476285 \n",
      "Epoch:42 Loss:0.8196420970257338 \n",
      "Epoch:43 Loss:0.8081950346134477 \n",
      "Epoch:44 Loss:0.7969802387042003 \n",
      "Epoch:45 Loss:0.7859926095428105 \n",
      "Epoch:46 Loss:0.7752271658624545 \n",
      "Epoch:47 Loss:0.7646790419971027 \n",
      "Epoch:48 Loss:0.7543434850674088 \n",
      "Epoch:49 Loss:0.7442158522381337 \n",
      "Epoch:50 Loss:0.734291608045192 \n",
      "Epoch:51 Loss:0.7245663217904991 \n",
      "Epoch:52 Loss:0.7150356650028303 \n",
      "Epoch:53 Loss:0.7056954089629406 \n",
      "Epoch:54 Loss:0.6965414222912758 \n",
      "Epoch:55 Loss:0.6875696685966077 \n",
      "Epoch:56 Loss:0.6787762041840086 \n",
      "Epoch:57 Loss:0.6701571758206013 \n",
      "Epoch:58 Loss:0.6617088185575682 \n",
      "Epoch:59 Loss:0.6534274536069548 \n",
      "Epoch:60 Loss:0.6453094862718203 \n",
      "Epoch:61 Loss:0.6373514039283559 \n",
      "Epoch:62 Loss:0.6295497740585971 \n",
      "Epoch:63 Loss:0.6219012423324234 \n",
      "Epoch:64 Loss:0.6144025307375569 \n",
      "Epoch:65 Loss:0.6070504357562998 \n",
      "Epoch:66 Loss:0.5998418265878106 \n",
      "Epoch:67 Loss:0.5927736434147239 \n",
      "Epoch:68 Loss:0.5858428957129638 \n",
      "Epoch:69 Loss:0.5790466606036349 \n",
      "Epoch:70 Loss:0.5723820812458927 \n",
      "Epoch:71 Loss:0.5658463652697389 \n",
      "Epoch:72 Loss:0.559436783247705 \n",
      "Epoch:73 Loss:0.5531506672044232 \n",
      "Epoch:74 Loss:0.5469854091630932 \n",
      "Epoch:75 Loss:0.5409384597279154 \n",
      "Epoch:76 Loss:0.5350073267015403 \n",
      "Epoch:77 Loss:0.5291895737366502 \n",
      "Epoch:78 Loss:0.5234828190207832 \n",
      "Epoch:79 Loss:0.5178847339935536 \n",
      "Epoch:80 Loss:0.5123930420954299 \n",
      "Epoch:81 Loss:0.5070055175472683 \n",
      "Epoch:82 Loss:0.5017199841598079 \n",
      "Epoch:83 Loss:0.49653431417236255 \n",
      "Epoch:84 Loss:0.49144642711996556 \n",
      "Epoch:85 Loss:0.4864542887282334 \n",
      "Epoch:86 Loss:0.4815559098352507 \n",
      "Epoch:87 Loss:0.47674934533977736 \n",
      "Epoch:88 Loss:0.4720326931751187 \n",
      "Epoch:89 Loss:0.46740409330799043 \n",
      "Epoch:90 Loss:0.4628617267617628 \n",
      "Epoch:91 Loss:0.4584038146634468 \n",
      "Epoch:92 Loss:0.4540286173138293 \n",
      "Epoch:93 Loss:0.44973443328016927 \n",
      "Epoch:94 Loss:0.4455195985108853 \n",
      "Epoch:95 Loss:0.44138248547167575 \n",
      "Epoch:96 Loss:0.43732150230252576 \n",
      "Epoch:97 Loss:0.43333509199508835 \n",
      "Epoch:98 Loss:0.4294217315899088 \n",
      "Epoch:99 Loss:0.4255799313930059 \n",
      "Epoch:100 Loss:0.42180823421131186 \n",
      "Epoch:101 Loss:0.41810521460650996 \n",
      "Epoch:102 Loss:0.4144694781667952 \n",
      "Epoch:103 Loss:0.410899660796115 \n",
      "Epoch:104 Loss:0.40739442802045017 \n",
      "Epoch:105 Loss:0.4039524743107177 \n",
      "Epoch:106 Loss:0.40057252242185876 \n",
      "Epoch:107 Loss:0.39725332274773456 \n",
      "Epoch:108 Loss:0.3939936526914148 \n",
      "Epoch:109 Loss:0.3907923160504847 \n",
      "Epoch:110 Loss:0.38764814241699597 \n",
      "Epoch:111 Loss:0.38455998659169305 \n",
      "Epoch:112 Loss:0.3815267280121662 \n",
      "Epoch:113 Loss:0.3785472701945803 \n",
      "Epoch:114 Loss:0.3756205401886467 \n",
      "Epoch:115 Loss:0.372745488045506 \n",
      "Epoch:116 Loss:0.3699210862982075 \n",
      "Epoch:117 Loss:0.36714632945446957 \n",
      "Epoch:118 Loss:0.3644202335014187 \n",
      "Epoch:119 Loss:0.36174183542201366 \n",
      "Epoch:120 Loss:0.3591101927228657 \n",
      "Epoch:121 Loss:0.35652438297317146 \n",
      "Epoch:122 Loss:0.3539835033544932 \n",
      "Epoch:123 Loss:0.3514866702211092 \n",
      "Epoch:124 Loss:0.3490330186706832 \n",
      "Epoch:125 Loss:0.34662170212499915 \n",
      "Epoch:126 Loss:0.344251891920509 \n",
      "Epoch:127 Loss:0.3419227769084602 \n",
      "Epoch:128 Loss:0.3396335630643666 \n",
      "Epoch:129 Loss:0.337383473106592 \n",
      "Epoch:130 Loss:0.33517174612382883 \n",
      "Epoch:131 Loss:0.33299763721125253 \n",
      "Epoch:132 Loss:0.33086041711513964 \n",
      "Epoch:133 Loss:0.32875937188574617 \n",
      "Epoch:134 Loss:0.3266938025382474 \n",
      "Epoch:135 Loss:0.3246630247215367 \n",
      "Epoch:136 Loss:0.3226663683947004 \n",
      "Epoch:137 Loss:0.32070317751097854 \n",
      "Epoch:138 Loss:0.31877280970903454 \n",
      "Epoch:139 Loss:0.31687463601135035 \n",
      "Epoch:140 Loss:0.31500804052958314 \n",
      "Epoch:141 Loss:0.31317242017671243 \n",
      "Epoch:142 Loss:0.3113671843858097 \n",
      "Epoch:143 Loss:0.3095917548352821 \n",
      "Epoch:144 Loss:0.30784556518042244 \n",
      "Epoch:145 Loss:0.3061280607911225 \n",
      "Epoch:146 Loss:0.30443869849559974 \n",
      "Epoch:147 Loss:0.3027769463299924 \n",
      "Epoch:148 Loss:0.30114228329368203 \n",
      "Epoch:149 Loss:0.2995341991102112 \n",
      "Epoch:150 Loss:0.2979521939936548 \n",
      "Epoch:151 Loss:0.2963957784203253 \n",
      "Epoch:152 Loss:0.2948644729056734 \n",
      "Epoch:153 Loss:0.29335780778627063 \n",
      "Epoch:154 Loss:0.2918753230067471 \n",
      "Epoch:155 Loss:0.2904165679115685 \n",
      "Epoch:156 Loss:0.28898110104153724 \n",
      "Epoch:157 Loss:0.28756848993490836 \n",
      "Epoch:158 Loss:0.28617831093300483 \n",
      "Epoch:159 Loss:0.2848101489902339 \n",
      "Epoch:160 Loss:0.2834635974883928 \n",
      "Epoch:161 Loss:0.2821382580551695 \n",
      "Epoch:162 Loss:0.28083374038673425 \n",
      "Epoch:163 Loss:0.2795496620743287 \n",
      "Epoch:164 Loss:0.27828564843475734 \n",
      "Epoch:165 Loss:0.27704133234469075 \n",
      "Epoch:166 Loss:0.2758163540786876 \n",
      "Epoch:167 Loss:0.2746103611508562 \n",
      "Epoch:168 Loss:0.2734230081600588 \n",
      "Epoch:169 Loss:0.2722539566385873 \n",
      "Epoch:170 Loss:0.2711028749042216 \n",
      "Epoch:171 Loss:0.2699694379155941 \n",
      "Epoch:172 Loss:0.26885332713078286 \n",
      "Epoch:173 Loss:0.2677542303690618 \n",
      "Epoch:174 Loss:0.266671841675726 \n",
      "Epoch:175 Loss:0.26560586118992974 \n",
      "Epoch:176 Loss:0.2645559950154621 \n",
      "Epoch:177 Loss:0.26352195509439325 \n",
      "Epoch:178 Loss:0.26250345908352424 \n",
      "Epoch:179 Loss:0.2615002302335773 \n",
      "Epoch:180 Loss:0.2605119972710615 \n",
      "Epoch:181 Loss:0.25953849428275166 \n",
      "Epoch:182 Loss:0.25857946060272236 \n",
      "Epoch:183 Loss:0.2576346407018752 \n",
      "Epoch:184 Loss:0.25670378407990435 \n",
      "Epoch:185 Loss:0.25578664515964356 \n",
      "Epoch:186 Loss:0.2548829831837382 \n",
      "Epoch:187 Loss:0.253992562113593 \n",
      "Epoch:188 Loss:0.25311515053053657 \n",
      "Epoch:189 Loss:0.2522505215391616 \n",
      "Epoch:190 Loss:0.25139845267277916 \n",
      "Epoch:191 Loss:0.2505587258009492 \n",
      "Epoch:192 Loss:0.24973112703903444 \n",
      "Epoch:193 Loss:0.24891544665973167 \n",
      "Epoch:194 Loss:0.2481114790065365 \n",
      "Epoch:195 Loss:0.24731902240909742 \n",
      "Epoch:196 Loss:0.2465378791004174 \n",
      "Epoch:197 Loss:0.24576785513585528 \n",
      "Epoch:198 Loss:0.2450087603138955 \n",
      "Epoch:199 Loss:0.24426040809863808 \n",
      "Epoch:200 Loss:0.24352261554397273 \n",
      "Epoch:201 Loss:0.24279520321939896 \n",
      "Epoch:202 Loss:0.2420779951374569 \n",
      "Epoch:203 Loss:0.24137081868272628 \n",
      "Epoch:204 Loss:0.2406735045423665 \n",
      "Epoch:205 Loss:0.23998588663815676 \n",
      "Epoch:206 Loss:0.2393078020600038 \n",
      "Epoch:207 Loss:0.23863909100088612 \n",
      "Epoch:208 Loss:0.23797959669320196 \n",
      "Epoch:209 Loss:0.23732916534648477 \n",
      "Epoch:210 Loss:0.236687646086465 \n",
      "Epoch:211 Loss:0.23605489089543702 \n",
      "Epoch:212 Loss:0.23543075455391066 \n",
      "Epoch:213 Loss:0.23481509458351457 \n",
      "Epoch:214 Loss:0.23420777119112246 \n",
      "Epoch:215 Loss:0.23360864721417773 \n",
      "Epoch:216 Loss:0.2330175880671896 \n",
      "Epoch:217 Loss:0.2324344616893713 \n",
      "Epoch:218 Loss:0.23185913849339787 \n",
      "Epoch:219 Loss:0.23129149131525797 \n",
      "Epoch:220 Loss:0.23073139536517656 \n",
      "Epoch:221 Loss:0.23017872817957938 \n",
      "Epoch:222 Loss:0.22963336957408612 \n",
      "Epoch:223 Loss:0.22909520159749666 \n",
      "Epoch:224 Loss:0.22856410848676026 \n",
      "Epoch:225 Loss:0.22803997662289885 \n",
      "Epoch:226 Loss:0.22752269448786475 \n",
      "Epoch:227 Loss:0.22701215262231308 \n",
      "Epoch:228 Loss:0.22650824358427027 \n",
      "Epoch:229 Loss:0.22601086190867256 \n",
      "Epoch:230 Loss:0.2255199040677636 \n",
      "Epoch:231 Loss:0.225035268432327 \n",
      "Epoch:232 Loss:0.22455685523373603 \n",
      "Epoch:233 Loss:0.2240845665268044 \n",
      "Epoch:234 Loss:0.22361830615341843 \n",
      "Epoch:235 Loss:0.22315797970693477 \n",
      "Epoch:236 Loss:0.22270349449732693 \n",
      "Epoch:237 Loss:0.22225475951706283 \n",
      "Epoch:238 Loss:0.22181168540769988 \n",
      "Epoch:239 Loss:0.22137418442717832 \n",
      "Epoch:240 Loss:0.22094217041780156 \n",
      "Epoch:241 Loss:0.22051555877488624 \n",
      "Epoch:242 Loss:0.22009426641606622 \n",
      "Epoch:243 Loss:0.2196782117512394 \n",
      "Epoch:244 Loss:0.21926731465314242 \n",
      "Epoch:245 Loss:0.218861496428536 \n",
      "Epoch:246 Loss:0.21846067978999373 \n",
      "Epoch:247 Loss:0.21806478882827737 \n",
      "Epoch:248 Loss:0.21767374898528424 \n",
      "Epoch:249 Loss:0.2172874870275608 \n",
      "Epoch:250 Loss:0.21690593102036212 \n",
      "Epoch:251 Loss:0.21652901030225255 \n",
      "Epoch:252 Loss:0.21615665546022994 \n",
      "Epoch:253 Loss:0.21578879830536832 \n",
      "Epoch:254 Loss:0.21542537184896063 \n",
      "Epoch:255 Loss:0.21506631027915674 \n",
      "Epoch:256 Loss:0.21471154893808436 \n",
      "Epoch:257 Loss:0.21436102429943976 \n",
      "Epoch:258 Loss:0.2140146739465429 \n",
      "Epoch:259 Loss:0.2136724365508425 \n",
      "Epoch:260 Loss:0.21333425185086455 \n",
      "Epoch:261 Loss:0.21300006063159266 \n",
      "Epoch:262 Loss:0.21266980470427296 \n",
      "Epoch:263 Loss:0.212343426886633 \n",
      "Epoch:264 Loss:0.21202087098350536 \n",
      "Epoch:265 Loss:0.21170208176784966 \n",
      "Epoch:266 Loss:0.21138700496216137 \n",
      "Epoch:267 Loss:0.21107558722026262 \n",
      "Epoch:268 Loss:0.2107677761094626 \n",
      "Epoch:269 Loss:0.2104635200930844 \n",
      "Epoch:270 Loss:0.21016276851334706 \n",
      "Epoch:271 Loss:0.209865471574595 \n",
      "Epoch:272 Loss:0.20957158032687304 \n",
      "Epoch:273 Loss:0.2092810466498296 \n",
      "Epoch:274 Loss:0.20899382323695206 \n",
      "Epoch:275 Loss:0.20870986358011898 \n",
      "Epoch:276 Loss:0.20842912195446786 \n",
      "Epoch:277 Loss:0.20815155340356672 \n",
      "Epoch:278 Loss:0.2078771137248889 \n",
      "Epoch:279 Loss:0.20760575945557916 \n",
      "Epoch:280 Loss:0.2073374478585103 \n",
      "Epoch:281 Loss:0.20707213690861678 \n",
      "Epoch:282 Loss:0.20680978527950888 \n",
      "Epoch:283 Loss:0.20655035233035315 \n",
      "Epoch:284 Loss:0.20629379809301931 \n",
      "Epoch:285 Loss:0.20604008325948334 \n",
      "Epoch:286 Loss:0.20578916916948595 \n",
      "Epoch:287 Loss:0.2055410177984374 \n",
      "Epoch:288 Loss:0.20529559174556536 \n",
      "Epoch:289 Loss:0.20505285422230046 \n",
      "Epoch:290 Loss:0.20481276904089432 \n",
      "Epoch:291 Loss:0.2045753006032647 \n",
      "Epoch:292 Loss:0.20434041389006422 \n",
      "Epoch:293 Loss:0.20410807444996734 \n",
      "Epoch:294 Loss:0.20387824838916999 \n",
      "Epoch:295 Loss:0.20365090236109992 \n",
      "Epoch:296 Loss:0.20342600355633117 \n",
      "Epoch:297 Loss:0.2032035196926981 \n",
      "Epoch:298 Loss:0.20298341900560865 \n",
      "Epoch:299 Loss:0.20276567023854616 \n",
      "Epoch:300 Loss:0.20255024263376256 \n",
      "Epoch:301 Loss:0.2023371059231548 \n",
      "Epoch:302 Loss:0.2021262303193223 \n",
      "Epoch:303 Loss:0.20191758650679936 \n",
      "Epoch:304 Loss:0.2017111456334641 \n",
      "Epoch:305 Loss:0.20150687930211372 \n",
      "Epoch:306 Loss:0.20130475956220817 \n",
      "Epoch:307 Loss:0.20110475890177498 \n",
      "Epoch:308 Loss:0.2009068502394741 \n",
      "Epoch:309 Loss:0.20071100691681867 \n",
      "Epoch:310 Loss:0.20051720269054774 \n",
      "Epoch:311 Loss:0.20032541172515042 \n",
      "Epoch:312 Loss:0.2001356085855338 \n",
      "Epoch:313 Loss:0.1999477682298381 \n",
      "Epoch:314 Loss:0.19976186600238843 \n",
      "Epoch:315 Loss:0.19957787762678714 \n",
      "Epoch:316 Loss:0.19939577919913895 \n",
      "Epoch:317 Loss:0.19921554718141096 \n",
      "Epoch:318 Loss:0.1990371583949183 \n",
      "Epoch:319 Loss:0.19886059001393913 \n",
      "Epoch:320 Loss:0.19868581955945386 \n",
      "Epoch:321 Loss:0.19851282489300381 \n",
      "Epoch:322 Loss:0.1983415842106712 \n",
      "Epoch:323 Loss:0.19817207603717468 \n",
      "Epoch:324 Loss:0.1980042792200801 \n",
      "Epoch:325 Loss:0.19783817292412004 \n",
      "Epoch:326 Loss:0.19767373662562884 \n",
      "Epoch:327 Loss:0.19751095010707978 \n",
      "Epoch:328 Loss:0.19734979345172882 \n",
      "Epoch:329 Loss:0.1971902470383641 \n",
      "Epoch:330 Loss:0.19703229153615276 \n",
      "Epoch:331 Loss:0.19687590789958823 \n",
      "Epoch:332 Loss:0.19672107736353692 \n",
      "Epoch:333 Loss:0.19656778143837403 \n",
      "Epoch:334 Loss:0.19641600190521885 \n",
      "Epoch:335 Loss:0.19626572081125754 \n",
      "Epoch:336 Loss:0.19611692046515486 \n",
      "Epoch:337 Loss:0.1959695834325566 \n",
      "Epoch:338 Loss:0.1958236925316747 \n",
      "Epoch:339 Loss:0.19567923082895702 \n",
      "Epoch:340 Loss:0.19553618163484118 \n",
      "Epoch:341 Loss:0.1953945284995867 \n",
      "Epoch:342 Loss:0.19525425520918818 \n",
      "Epoch:343 Loss:0.19511534578136436 \n",
      "Epoch:344 Loss:0.19497778446162412 \n",
      "Epoch:345 Loss:0.19484155571940667 \n",
      "Epoch:346 Loss:0.19470664424429393 \n",
      "Epoch:347 Loss:0.19457303494229547 \n",
      "Epoch:348 Loss:0.1944407129322027 \n",
      "Epoch:349 Loss:0.1943096635420115 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:350 Loss:0.19417987230541267 \n",
      "Epoch:351 Loss:0.19405132495834818 \n",
      "Epoch:352 Loss:0.1939240074356306 \n",
      "Epoch:353 Loss:0.1937979058676288 \n",
      "Epoch:354 Loss:0.19367300657701217 \n",
      "Epoch:355 Loss:0.19354929607555793 \n",
      "Epoch:356 Loss:0.19342676106101753 \n",
      "Epoch:357 Loss:0.19330538841404052 \n",
      "Epoch:358 Loss:0.19318516519515716 \n",
      "Epoch:359 Loss:0.19306607864181544 \n",
      "Epoch:360 Loss:0.1929481161654749 \n",
      "Epoch:361 Loss:0.19283126534875197 \n",
      "Epoch:362 Loss:0.19271551394262088 \n",
      "Epoch:363 Loss:0.1926008498636639 \n",
      "Epoch:364 Loss:0.19248726119137405 \n",
      "Epoch:365 Loss:0.19237473616550615 \n",
      "Epoch:366 Loss:0.19226326318347772 \n",
      "Epoch:367 Loss:0.1921528307978176 \n",
      "Epoch:368 Loss:0.1920434277136603 \n",
      "Epoch:369 Loss:0.1919350427862873 \n",
      "Epoch:370 Loss:0.19182766501871382 \n",
      "Epoch:371 Loss:0.19172128355931783 \n",
      "Epoch:372 Loss:0.1916158876995146 \n",
      "Epoch:373 Loss:0.19151146687147197 \n",
      "Epoch:374 Loss:0.19140801064586765 \n",
      "Epoch:375 Loss:0.19130550872968863 \n",
      "Epoch:376 Loss:0.19120395096406775 \n",
      "Epoch:377 Loss:0.1911033273221624 \n",
      "Epoch:378 Loss:0.1910036279070696 \n",
      "Epoch:379 Loss:0.19090484294978016 \n",
      "Epoch:380 Loss:0.19080696280716855 \n",
      "Epoch:381 Loss:0.19070997796002 \n",
      "Epoch:382 Loss:0.19061387901109195 \n",
      "Epoch:383 Loss:0.1905186566832121 \n",
      "Epoch:384 Loss:0.19042430181740863 \n",
      "Epoch:385 Loss:0.19033080537107527 \n",
      "Epoch:386 Loss:0.1902381584161687 \n",
      "Epoch:387 Loss:0.19014635213743833 \n",
      "Epoch:388 Loss:0.1900553778306871 \n",
      "Epoch:389 Loss:0.18996522690106382 \n",
      "Epoch:390 Loss:0.1898758908613863 \n",
      "Epoch:391 Loss:0.18978736133049223 \n",
      "Epoch:392 Loss:0.18969963003162232 \n",
      "Epoch:393 Loss:0.18961268879082935 \n",
      "Epoch:394 Loss:0.189526529535417 \n",
      "Epoch:395 Loss:0.1894411442924051 \n",
      "Epoch:396 Loss:0.18935652518702262 \n",
      "Epoch:397 Loss:0.18927266444122742 \n",
      "Epoch:398 Loss:0.18918955437225016 \n",
      "Epoch:399 Loss:0.18910718739116686 \n",
      "Epoch:400 Loss:0.1890255560014931 \n",
      "Epoch:401 Loss:0.18894465279780528 \n",
      "Epoch:402 Loss:0.18886447046438462 \n",
      "Epoch:403 Loss:0.1887850017738843 \n",
      "Epoch:404 Loss:0.18870623958602198 \n",
      "Epoch:405 Loss:0.18862817684629243 \n",
      "Epoch:406 Loss:0.18855080658470377 \n",
      "Epoch:407 Loss:0.1884741219145355 \n",
      "Epoch:408 Loss:0.18839811603111822 \n",
      "Epoch:409 Loss:0.18832278221063256 \n",
      "Epoch:410 Loss:0.18824811380893167 \n",
      "Epoch:411 Loss:0.18817410426038145 \n",
      "Epoch:412 Loss:0.18810074707672178 \n",
      "Epoch:413 Loss:0.18802803584594754 \n",
      "Epoch:414 Loss:0.18795596423120675 \n",
      "Epoch:415 Loss:0.1878845259697212 \n",
      "Epoch:416 Loss:0.1878137148717207 \n",
      "Epoch:417 Loss:0.1877435248194 \n",
      "Epoch:418 Loss:0.1876739497658894 \n",
      "Epoch:419 Loss:0.18760498373424647 \n",
      "Epoch:420 Loss:0.1875366208164614 \n",
      "Epoch:421 Loss:0.1874688551724817 \n",
      "Epoch:422 Loss:0.18740168102925173 \n",
      "Epoch:423 Loss:0.18733509267976883 \n",
      "Epoch:424 Loss:0.18726908448215562 \n",
      "Epoch:425 Loss:0.18720365085874732 \n",
      "Epoch:426 Loss:0.1871387862951946 \n",
      "Epoch:427 Loss:0.18707448533958093 \n",
      "Epoch:428 Loss:0.1870107426015552 \n",
      "Epoch:429 Loss:0.1869475527514784 \n",
      "Epoch:430 Loss:0.18688491051958397 \n",
      "Epoch:431 Loss:0.18682281069515336 \n",
      "Epoch:432 Loss:0.18676124812570383 \n",
      "Epoch:433 Loss:0.18670021771618991 \n",
      "Epoch:434 Loss:0.18663971442821842 \n",
      "Epoch:435 Loss:0.186579733279276 \n",
      "Epoch:436 Loss:0.18652026934196958 \n",
      "Epoch:437 Loss:0.18646131774327906 \n",
      "Epoch:438 Loss:0.18640287366382144 \n",
      "Epoch:439 Loss:0.18634493233712854 \n",
      "Epoch:440 Loss:0.18628748904893472 \n",
      "Epoch:441 Loss:0.18623053913647752 \n",
      "Epoch:442 Loss:0.18617407798780802 \n",
      "Epoch:443 Loss:0.1861181010411147 \n",
      "Epoch:444 Loss:0.1860626037840554 \n",
      "Epoch:445 Loss:0.18600758175310175 \n",
      "Epoch:446 Loss:0.18595303053289364 \n",
      "Epoch:447 Loss:0.18589894575560428 \n",
      "Epoch:448 Loss:0.18584532310031499 \n",
      "Epoch:449 Loss:0.18579215829239962 \n",
      "Epoch:450 Loss:0.18573944710291979 \n",
      "Epoch:451 Loss:0.18568718534802836 \n",
      "Epoch:452 Loss:0.18563536888838386 \n",
      "Epoch:453 Loss:0.18558399362857303 \n",
      "Epoch:454 Loss:0.1855330555165424 \n",
      "Epoch:455 Loss:0.18548255054303925 \n",
      "Epoch:456 Loss:0.18543247474106164 \n",
      "Epoch:457 Loss:0.1853828241853161 \n",
      "Epoch:458 Loss:0.18533359499168445 \n",
      "Epoch:459 Loss:0.18528478331669837 \n",
      "Epoch:460 Loss:0.1852363853570231 \n",
      "Epoch:461 Loss:0.1851883973489483 \n",
      "Epoch:462 Loss:0.1851408155678859 \n",
      "Epoch:463 Loss:0.1850936363278787 \n",
      "Epoch:464 Loss:0.18504685598111245 \n",
      "Epoch:465 Loss:0.18500047091743912 \n",
      "Epoch:466 Loss:0.184954477563905 \n",
      "Epoch:467 Loss:0.1849088723842873 \n",
      "Epoch:468 Loss:0.18486365187863654 \n",
      "Epoch:469 Loss:0.18481881258282784 \n",
      "Epoch:470 Loss:0.1847743510681167 \n",
      "Epoch:471 Loss:0.18473026394070394 \n",
      "Epoch:472 Loss:0.18468654784130395 \n",
      "Epoch:473 Loss:0.184643199444724 \n",
      "Epoch:474 Loss:0.18460021545944463 \n",
      "Epoch:475 Loss:0.18455759262721025 \n",
      "Epoch:476 Loss:0.18451532772262508 \n",
      "Epoch:477 Loss:0.18447341755275287 \n",
      "Epoch:478 Loss:0.1844318589567254 \n",
      "Epoch:479 Loss:0.18439064880535577 \n",
      "Epoch:480 Loss:0.18434978400075605 \n",
      "Epoch:481 Loss:0.18430926147596322 \n",
      "Epoch:482 Loss:0.18426907819456764 \n",
      "Epoch:483 Loss:0.1842292311503498 \n",
      "Epoch:484 Loss:0.1841897173669204 \n",
      "Epoch:485 Loss:0.1841505338973657 \n",
      "Epoch:486 Loss:0.18411167782390064 \n",
      "Epoch:487 Loss:0.18407314625752208 \n",
      "Epoch:488 Loss:0.1840349363376727 \n",
      "Epoch:489 Loss:0.18399704523190547 \n",
      "Epoch:490 Loss:0.18395947013555464 \n",
      "Epoch:491 Loss:0.18392220827141204 \n",
      "Epoch:492 Loss:0.18388525688940693 \n",
      "Epoch:493 Loss:0.18384861326629015 \n",
      "Epoch:494 Loss:0.18381227470532438 \n",
      "Epoch:495 Loss:0.183776238535977 \n",
      "Epoch:496 Loss:0.18374050211361914 \n",
      "Epoch:497 Loss:0.18370506281922672 \n",
      "Epoch:498 Loss:0.183669918059088 \n",
      "Epoch:499 Loss:0.18363506526451356 \n",
      "Epoch:500 Loss:0.1836005018915513 \n",
      "Epoch:501 Loss:0.18356622542070472 \n",
      "Epoch:502 Loss:0.18353223335665625 \n",
      "Epoch:503 Loss:0.1834985232279931 \n",
      "Epoch:504 Loss:0.18346509258693727 \n",
      "Epoch:505 Loss:0.18343193900908047 \n",
      "Epoch:506 Loss:0.1833990600931208 \n",
      "Epoch:507 Loss:0.18336645346060423 \n",
      "Epoch:508 Loss:0.1833341167556702 \n",
      "Epoch:509 Loss:0.18330204764479863 \n",
      "Epoch:510 Loss:0.18327024381656265 \n",
      "Epoch:511 Loss:0.18323870298138342 \n",
      "Epoch:512 Loss:0.18320742287128802 \n",
      "Epoch:513 Loss:0.1831764012396723 \n",
      "Epoch:514 Loss:0.1831456358610644 \n",
      "Epoch:515 Loss:0.18311512453089432 \n",
      "Epoch:516 Loss:0.18308486506526386 \n",
      "Epoch:517 Loss:0.18305485530072152 \n",
      "Epoch:518 Loss:0.1830250930940396 \n",
      "Epoch:519 Loss:0.18299557632199454 \n",
      "Epoch:520 Loss:0.18296630288114993 \n",
      "Epoch:521 Loss:0.18293727068764276 \n",
      "Epoch:522 Loss:0.18290847767697174 \n",
      "Epoch:523 Loss:0.18287992180379 \n",
      "Epoch:524 Loss:0.1828516010416984 \n",
      "Epoch:525 Loss:0.18282351338304276 \n",
      "Epoch:526 Loss:0.18279565683871424 \n",
      "Epoch:527 Loss:0.18276802943795092 \n",
      "Epoch:528 Loss:0.18274062922814333 \n",
      "Epoch:529 Loss:0.1827134542746411 \n",
      "Epoch:530 Loss:0.18268650266056355 \n",
      "Epoch:531 Loss:0.18265977248661175 \n",
      "Epoch:532 Loss:0.18263326187088336 \n",
      "Epoch:533 Loss:0.18260696894868958 \n",
      "Epoch:534 Loss:0.18258089187237522 \n",
      "Epoch:535 Loss:0.18255502881113922 \n",
      "Epoch:536 Loss:0.18252937795086038 \n",
      "Epoch:537 Loss:0.18250393749392219 \n",
      "Epoch:538 Loss:0.18247870565904195 \n",
      "Epoch:539 Loss:0.18245368068110138 \n",
      "Epoch:540 Loss:0.1824288608109791 \n",
      "Epoch:541 Loss:0.1824042443153859 \n",
      "Epoch:542 Loss:0.18237982947670087 \n",
      "Epoch:543 Loss:0.18235561459281174 \n",
      "Epoch:544 Loss:0.18233159797695409 \n",
      "Epoch:545 Loss:0.18230777795755562 \n",
      "Epoch:546 Loss:0.18228415287808022 \n",
      "Epoch:547 Loss:0.18226072109687544 \n",
      "Epoch:548 Loss:0.1822374809870202 \n",
      "Epoch:549 Loss:0.18221443093617612 \n",
      "Epoch:550 Loss:0.1821915693464395 \n",
      "Epoch:551 Loss:0.18216889463419556 \n",
      "Epoch:552 Loss:0.18214640522997397 \n",
      "Epoch:553 Loss:0.18212409957830733 \n",
      "Epoch:554 Loss:0.18210197613758955 \n",
      "Epoch:555 Loss:0.18208003337993758 \n",
      "Epoch:556 Loss:0.18205826979105422 \n",
      "Epoch:557 Loss:0.18203668387009178 \n",
      "Epoch:558 Loss:0.18201527412951887 \n",
      "Epoch:559 Loss:0.18199403909498746 \n",
      "Epoch:560 Loss:0.18197297730520257 \n",
      "Epoch:561 Loss:0.18195208731179255 \n",
      "Epoch:562 Loss:0.1819313676791814 \n",
      "Epoch:563 Loss:0.18191081698446304 \n",
      "Epoch:564 Loss:0.1818904338172756 \n",
      "Epoch:565 Loss:0.18187021677967916 \n",
      "Epoch:566 Loss:0.18185016448603333 \n",
      "Epoch:567 Loss:0.1818302755628765 \n",
      "Epoch:568 Loss:0.18181054864880855 \n",
      "Epoch:569 Loss:0.18179098239437022 \n",
      "Epoch:570 Loss:0.18177157546192968 \n",
      "Epoch:571 Loss:0.18175232652556658 \n",
      "Epoch:572 Loss:0.18173323427095756 \n",
      "Epoch:573 Loss:0.1817142973952652 \n",
      "Epoch:574 Loss:0.18169551460702676 \n",
      "Epoch:575 Loss:0.1816768846260436 \n",
      "Epoch:576 Loss:0.18165840618327397 \n",
      "Epoch:577 Loss:0.18164007802072463 \n",
      "Epoch:578 Loss:0.1816218988913453 \n",
      "Epoch:579 Loss:0.18160386755892402 \n",
      "Epoch:580 Loss:0.18158598279798294 \n",
      "Epoch:581 Loss:0.18156824339367633 \n",
      "Epoch:582 Loss:0.18155064814168895 \n",
      "Epoch:583 Loss:0.18153319584813604 \n",
      "Epoch:584 Loss:0.18151588532946386 \n",
      "Epoch:585 Loss:0.18149871541235207 \n",
      "Epoch:586 Loss:0.1814816849336167 \n",
      "Epoch:587 Loss:0.18146479274011468 \n",
      "Epoch:588 Loss:0.18144803768864817 \n",
      "Epoch:589 Loss:0.18143141864587176 \n",
      "Epoch:590 Loss:0.18141493448819906 \n",
      "Epoch:591 Loss:0.18139858410171195 \n",
      "Epoch:592 Loss:0.1813823663820689 \n",
      "Epoch:593 Loss:0.18136628023441617 \n",
      "Epoch:594 Loss:0.18135032457329808 \n",
      "Epoch:595 Loss:0.18133449832257034 \n",
      "Epoch:596 Loss:0.1813188004153124 \n",
      "Epoch:597 Loss:0.18130322979374272 \n",
      "Epoch:598 Loss:0.18128778540913246 \n",
      "Epoch:599 Loss:0.18127246622172208 \n",
      "Epoch:600 Loss:0.18125727120063884 \n",
      "Epoch:601 Loss:0.18124219932381375 \n",
      "Epoch:602 Loss:0.1812272495779004 \n",
      "Epoch:603 Loss:0.18121242095819448 \n",
      "Epoch:604 Loss:0.18119771246855498 \n",
      "Epoch:605 Loss:0.18118312312132384 \n",
      "Epoch:606 Loss:0.1811686519372495 \n",
      "Epoch:607 Loss:0.18115429794540897 \n",
      "Epoch:608 Loss:0.1811400601831317 \n",
      "Epoch:609 Loss:0.18112593769592436 \n",
      "Epoch:610 Loss:0.18111192953739555 \n",
      "Epoch:611 Loss:0.1810980347691823 \n",
      "Epoch:612 Loss:0.18108425246087723 \n",
      "Epoch:613 Loss:0.1810705816899553 \n",
      "Epoch:614 Loss:0.18105702154170278 \n",
      "Epoch:615 Loss:0.18104357110914623 \n",
      "Epoch:616 Loss:0.18103022949298242 \n",
      "Epoch:617 Loss:0.18101699580150854 \n",
      "Epoch:618 Loss:0.18100386915055386 \n",
      "Epoch:619 Loss:0.18099084866341159 \n",
      "Epoch:620 Loss:0.18097793347077162 \n",
      "Epoch:621 Loss:0.18096512271065376 \n",
      "Epoch:622 Loss:0.18095241552834168 \n",
      "Epoch:623 Loss:0.18093981107631807 \n",
      "Epoch:624 Loss:0.18092730851419936 \n",
      "Epoch:625 Loss:0.18091490700867266 \n",
      "Epoch:626 Loss:0.18090260573343167 \n",
      "Epoch:627 Loss:0.18089040386911445 \n",
      "Epoch:628 Loss:0.18087830060324103 \n",
      "Epoch:629 Loss:0.18086629513015218 \n",
      "Epoch:630 Loss:0.18085438665094877 \n",
      "Epoch:631 Loss:0.1808425743734314 \n",
      "Epoch:632 Loss:0.180830857512041 \n",
      "Epoch:633 Loss:0.18081923528779933 \n",
      "Epoch:634 Loss:0.1808077069282512 \n",
      "Epoch:635 Loss:0.18079627166740633 \n",
      "Epoch:636 Loss:0.18078492874568222 \n",
      "Epoch:637 Loss:0.1807736774098472 \n",
      "Epoch:638 Loss:0.1807625169129648 \n",
      "Epoch:639 Loss:0.18075144651433803 \n",
      "Epoch:640 Loss:0.18074046547945347 \n",
      "Epoch:641 Loss:0.18072957307992835 \n",
      "Epoch:642 Loss:0.18071876859345562 \n",
      "Epoch:643 Loss:0.18070805130375062 \n",
      "Epoch:644 Loss:0.18069742050049828 \n",
      "Epoch:645 Loss:0.18068687547930076 \n",
      "Epoch:646 Loss:0.18067641554162564 \n",
      "Epoch:647 Loss:0.18066603999475472 \n",
      "Epoch:648 Loss:0.18065574815173238 \n",
      "Epoch:649 Loss:0.1806455393313164 \n",
      "Epoch:650 Loss:0.18063541285792684 \n",
      "Epoch:651 Loss:0.1806253680615976 \n",
      "Epoch:652 Loss:0.18061540427792722 \n",
      "Epoch:653 Loss:0.18060552084802997 \n",
      "Epoch:654 Loss:0.1805957171184885 \n",
      "Epoch:655 Loss:0.1805859924413059 \n",
      "Epoch:656 Loss:0.18057634617385873 \n",
      "Epoch:657 Loss:0.18056677767885032 \n",
      "Epoch:658 Loss:0.18055728632426507 \n",
      "Epoch:659 Loss:0.18054787148332196 \n",
      "Epoch:660 Loss:0.18053853253442975 \n",
      "Epoch:661 Loss:0.1805292688611418 \n",
      "Epoch:662 Loss:0.1805200798521117 \n",
      "Epoch:663 Loss:0.18051096490104993 \n",
      "Epoch:664 Loss:0.18050192340667848 \n",
      "Epoch:665 Loss:0.18049295477268998 \n",
      "Epoch:666 Loss:0.18048405840770262 \n",
      "Epoch:667 Loss:0.18047523372521979 \n",
      "Epoch:668 Loss:0.18046648014358632 \n",
      "Epoch:669 Loss:0.1804577970859483 \n",
      "Epoch:670 Loss:0.18044918398021093 \n",
      "Epoch:671 Loss:0.1804406402589977 \n",
      "Epoch:672 Loss:0.18043216535961054 \n",
      "Epoch:673 Loss:0.18042375872398986 \n",
      "Epoch:674 Loss:0.18041541979867348 \n",
      "Epoch:675 Loss:0.18040714803475913 \n",
      "Epoch:676 Loss:0.1803989428878638 \n",
      "Epoch:677 Loss:0.18039080381808673 \n",
      "Epoch:678 Loss:0.18038273028996937 \n",
      "Epoch:679 Loss:0.18037472177245942 \n",
      "Epoch:680 Loss:0.18036677773887172 \n",
      "Epoch:681 Loss:0.1803588976668518 \n",
      "Epoch:682 Loss:0.18035108103833866 \n",
      "Epoch:683 Loss:0.18034332733952896 \n",
      "Epoch:684 Loss:0.18033563606083977 \n",
      "Epoch:685 Loss:0.1803280066968736 \n",
      "Epoch:686 Loss:0.18032043874638226 \n",
      "Epoch:687 Loss:0.18031293171223195 \n",
      "Epoch:688 Loss:0.18030548510136837 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:689 Loss:0.18029809842478253 \n",
      "Epoch:690 Loss:0.18029077119747536 \n",
      "Epoch:691 Loss:0.180283502938425 \n",
      "Epoch:692 Loss:0.18027629317055227 \n",
      "Epoch:693 Loss:0.18026914142068834 \n",
      "Epoch:694 Loss:0.18026204721954045 \n",
      "Epoch:695 Loss:0.18025501010166015 \n",
      "Epoch:696 Loss:0.18024802960541036 \n",
      "Epoch:697 Loss:0.18024110527293363 \n",
      "Epoch:698 Loss:0.18023423665011964 \n",
      "Epoch:699 Loss:0.1802274232865747 \n",
      "Epoch:700 Loss:0.18022066473558904 \n",
      "Epoch:701 Loss:0.18021396055410716 \n",
      "Epoch:702 Loss:0.1802073103026962 \n",
      "Epoch:703 Loss:0.18020071354551598 \n",
      "Epoch:704 Loss:0.18019416985028866 \n",
      "Epoch:705 Loss:0.18018767878826863 \n",
      "Epoch:706 Loss:0.18018123993421326 \n",
      "Epoch:707 Loss:0.18017485286635312 \n",
      "Epoch:708 Loss:0.18016851716636337 \n",
      "Epoch:709 Loss:0.18016223241933407 \n",
      "Epoch:710 Loss:0.1801559982137427 \n",
      "Epoch:711 Loss:0.18014981414142478 \n",
      "Epoch:712 Loss:0.18014367979754636 \n",
      "Epoch:713 Loss:0.18013759478057614 \n",
      "Epoch:714 Loss:0.1801315586922575 \n",
      "Epoch:715 Loss:0.18012557113758118 \n",
      "Epoch:716 Loss:0.1801196317247591 \n",
      "Epoch:717 Loss:0.1801137400651961 \n",
      "Epoch:718 Loss:0.18010789577346395 \n",
      "Epoch:719 Loss:0.18010209846727543 \n",
      "Epoch:720 Loss:0.18009634776745698 \n",
      "Epoch:721 Loss:0.1800906432979242 \n",
      "Epoch:722 Loss:0.18008498468565456 \n",
      "Epoch:723 Loss:0.18007937156066306 \n",
      "Epoch:724 Loss:0.1800738035559767 \n",
      "Epoch:725 Loss:0.1800682803076092 \n",
      "Epoch:726 Loss:0.1800628014545364 \n",
      "Epoch:727 Loss:0.18005736663867164 \n",
      "Epoch:728 Loss:0.18005197550484062 \n",
      "Epoch:729 Loss:0.18004662770075877 \n",
      "Epoch:730 Loss:0.18004132287700553 \n",
      "Epoch:731 Loss:0.18003606068700218 \n",
      "Epoch:732 Loss:0.1800308407869869 \n",
      "Epoch:733 Loss:0.1800256628359925 \n",
      "Epoch:734 Loss:0.18002052649582231 \n",
      "Epoch:735 Loss:0.18001543143102794 \n",
      "Epoch:736 Loss:0.1800103773088864 \n",
      "Epoch:737 Loss:0.1800053637993772 \n",
      "Epoch:738 Loss:0.18000039057516043 \n",
      "Epoch:739 Loss:0.17999545731155403 \n",
      "Epoch:740 Loss:0.17999056368651276 \n",
      "Epoch:741 Loss:0.17998570938060496 \n",
      "Epoch:742 Loss:0.1799808940769928 \n",
      "Epoch:743 Loss:0.17997611746140893 \n",
      "Epoch:744 Loss:0.17997137922213666 \n",
      "Epoch:745 Loss:0.1799666790499884 \n",
      "Epoch:746 Loss:0.17996201663828454 \n",
      "Epoch:747 Loss:0.17995739168283356 \n",
      "Epoch:748 Loss:0.17995280388191046 \n",
      "Epoch:749 Loss:0.1799482529362369 \n",
      "Epoch:750 Loss:0.17994373854896192 \n",
      "Epoch:751 Loss:0.1799392604256401 \n",
      "Epoch:752 Loss:0.17993481827421345 \n",
      "Epoch:753 Loss:0.17993041180499092 \n",
      "Epoch:754 Loss:0.17992604073062865 \n",
      "Epoch:755 Loss:0.1799217047661117 \n",
      "Epoch:756 Loss:0.17991740362873376 \n",
      "Epoch:757 Loss:0.17991313703807943 \n",
      "Epoch:758 Loss:0.17990890471600354 \n",
      "Epoch:759 Loss:0.17990470638661452 \n",
      "Epoch:760 Loss:0.1799005417762545 \n",
      "Epoch:761 Loss:0.1798964106134814 \n",
      "Epoch:762 Loss:0.17989231262905103 \n",
      "Epoch:763 Loss:0.17988824755589874 \n",
      "Epoch:764 Loss:0.17988421512912123 \n",
      "Epoch:765 Loss:0.17988021508595947 \n",
      "Epoch:766 Loss:0.17987624716578057 \n",
      "Epoch:767 Loss:0.1798723111100609 \n",
      "Epoch:768 Loss:0.17986840666236825 \n",
      "Epoch:769 Loss:0.17986453356834448 \n",
      "Epoch:770 Loss:0.17986069157569018 \n",
      "Epoch:771 Loss:0.1798568804341453 \n",
      "Epoch:772 Loss:0.17985309989547407 \n",
      "Epoch:773 Loss:0.17984934971344854 \n",
      "Epoch:774 Loss:0.17984562964383122 \n",
      "Epoch:775 Loss:0.17984193944435975 \n",
      "Epoch:776 Loss:0.17983827887472953 \n",
      "Epoch:777 Loss:0.17983464769657895 \n",
      "Epoch:778 Loss:0.1798310456734729 \n",
      "Epoch:779 Loss:0.17982747257088708 \n",
      "Epoch:780 Loss:0.1798239281561923 \n",
      "Epoch:781 Loss:0.17982041219863892 \n",
      "Epoch:782 Loss:0.1798169244693424 \n",
      "Epoch:783 Loss:0.17981346474126644 \n",
      "Epoch:784 Loss:0.17981003278920932 \n",
      "Epoch:785 Loss:0.17980662838978811 \n",
      "Epoch:786 Loss:0.17980325132142427 \n",
      "Epoch:787 Loss:0.17979990136432852 \n",
      "Epoch:788 Loss:0.1797965783004868 \n",
      "Epoch:789 Loss:0.17979328191364502 \n",
      "Epoch:790 Loss:0.17979001198929562 \n",
      "Epoch:791 Loss:0.17978676831466228 \n",
      "Epoch:792 Loss:0.179783550678687 \n",
      "Epoch:793 Loss:0.1797803588720148 \n",
      "Epoch:794 Loss:0.17977719268698103 \n",
      "Epoch:795 Loss:0.17977405191759668 \n",
      "Epoch:796 Loss:0.17977093635953537 \n",
      "Epoch:797 Loss:0.1797678458101195 \n",
      "Epoch:798 Loss:0.1797647800683066 \n",
      "Epoch:799 Loss:0.17976173893467684 \n",
      "Epoch:800 Loss:0.17975872221141878 \n",
      "Epoch:801 Loss:0.1797557297023169 \n",
      "Epoch:802 Loss:0.17975276121273856 \n",
      "Epoch:803 Loss:0.1797498165496209 \n",
      "Epoch:804 Loss:0.17974689552145853 \n",
      "Epoch:805 Loss:0.1797439979382899 \n",
      "Epoch:806 Loss:0.17974112361168598 \n",
      "Epoch:807 Loss:0.17973827235473716 \n",
      "Epoch:808 Loss:0.1797354439820406 \n",
      "Epoch:809 Loss:0.17973263830968852 \n",
      "Epoch:810 Loss:0.17972985515525586 \n",
      "Epoch:811 Loss:0.1797270943377881 \n",
      "Epoch:812 Loss:0.17972435567778974 \n",
      "Epoch:813 Loss:0.17972163899721186 \n",
      "Epoch:814 Loss:0.1797189441194405 \n",
      "Epoch:815 Loss:0.17971627086928554 \n",
      "Epoch:816 Loss:0.17971361907296873 \n",
      "Epoch:817 Loss:0.17971098855811207 \n",
      "Epoch:818 Loss:0.1797083791537265 \n",
      "Epoch:819 Loss:0.17970579069020118 \n",
      "Epoch:820 Loss:0.1797032229992916 \n",
      "Epoch:821 Loss:0.17970067591410854 \n",
      "Epoch:822 Loss:0.17969814926910804 \n",
      "Epoch:823 Loss:0.17969564290007886 \n",
      "Epoch:824 Loss:0.17969315664413338 \n",
      "Epoch:825 Loss:0.1796906903396957 \n",
      "Epoch:826 Loss:0.179688243826491 \n",
      "Epoch:827 Loss:0.17968581694553612 \n",
      "Epoch:828 Loss:0.17968340953912748 \n",
      "Epoch:829 Loss:0.17968102145083242 \n",
      "Epoch:830 Loss:0.1796786525254774 \n",
      "Epoch:831 Loss:0.17967630260913856 \n",
      "Epoch:832 Loss:0.17967397154913156 \n",
      "Epoch:833 Loss:0.1796716591940014 \n",
      "Epoch:834 Loss:0.17966936539351236 \n",
      "Epoch:835 Loss:0.17966708999863876 \n",
      "Epoch:836 Loss:0.1796648328615541 \n",
      "Epoch:837 Loss:0.17966259383562194 \n",
      "Epoch:838 Loss:0.17966037277538693 \n",
      "Epoch:839 Loss:0.17965816953656366 \n",
      "Epoch:840 Loss:0.17965598397602853 \n",
      "Epoch:841 Loss:0.17965381595181001 \n",
      "Epoch:842 Loss:0.17965166532307922 \n",
      "Epoch:843 Loss:0.17964953195014013 \n",
      "Epoch:844 Loss:0.17964741569442175 \n",
      "Epoch:845 Loss:0.17964531641846762 \n",
      "Epoch:846 Loss:0.17964323398592788 \n",
      "Epoch:847 Loss:0.17964116826154908 \n",
      "Epoch:848 Loss:0.17963911911116692 \n",
      "Epoch:849 Loss:0.17963708640169596 \n",
      "Epoch:850 Loss:0.17963507000112208 \n",
      "Epoch:851 Loss:0.17963306977849275 \n",
      "Epoch:852 Loss:0.17963108560390922 \n",
      "Epoch:853 Loss:0.17962911734851766 \n",
      "Epoch:854 Loss:0.17962716488450095 \n",
      "Epoch:855 Loss:0.17962522808506998 \n",
      "Epoch:856 Loss:0.17962330682445546 \n",
      "Epoch:857 Loss:0.17962140097790003 \n",
      "Epoch:858 Loss:0.17961951042164948 \n",
      "Epoch:859 Loss:0.179617635032945 \n",
      "Epoch:860 Loss:0.17961577469001527 \n",
      "Epoch:861 Loss:0.17961392927206826 \n",
      "Epoch:862 Loss:0.17961209865928301 \n",
      "Epoch:863 Loss:0.1796102827328027 \n",
      "Epoch:864 Loss:0.17960848137472576 \n",
      "Epoch:865 Loss:0.1796066944680993 \n",
      "Epoch:866 Loss:0.17960492189691013 \n",
      "Epoch:867 Loss:0.1796031635460783 \n",
      "Epoch:868 Loss:0.17960141930144943 \n",
      "Epoch:869 Loss:0.17959968904978646 \n",
      "Epoch:870 Loss:0.1795979726787631 \n",
      "Epoch:871 Loss:0.1795962700769557 \n",
      "Epoch:872 Loss:0.17959458113383697 \n",
      "Epoch:873 Loss:0.179592905739768 \n",
      "Epoch:874 Loss:0.17959124378599076 \n",
      "Epoch:875 Loss:0.17958959516462208 \n",
      "Epoch:876 Loss:0.17958795976864594 \n",
      "Epoch:877 Loss:0.17958633749190642 \n",
      "Epoch:878 Loss:0.17958472822910096 \n",
      "Epoch:879 Loss:0.17958313187577302 \n",
      "Epoch:880 Loss:0.1795815483283063 \n",
      "Epoch:881 Loss:0.1795799774839168 \n",
      "Epoch:882 Loss:0.17957841924064682 \n",
      "Epoch:883 Loss:0.1795768734973581 \n",
      "Epoch:884 Loss:0.179575340153725 \n",
      "Epoch:885 Loss:0.17957381911022852 \n",
      "Epoch:886 Loss:0.17957231026814893 \n",
      "Epoch:887 Loss:0.17957081352956045 \n",
      "Epoch:888 Loss:0.1795693287973235 \n",
      "Epoch:889 Loss:0.17956785597507954 \n",
      "Epoch:890 Loss:0.17956639496724422 \n",
      "Epoch:891 Loss:0.1795649456790015 \n",
      "Epoch:892 Loss:0.17956350801629656 \n",
      "Epoch:893 Loss:0.17956208188583073 \n",
      "Epoch:894 Loss:0.17956066719505512 \n",
      "Epoch:895 Loss:0.17955926385216406 \n",
      "Epoch:896 Loss:0.17955787176608964 \n",
      "Epoch:897 Loss:0.17955649084649553 \n",
      "Epoch:898 Loss:0.17955512100377144 \n",
      "Epoch:899 Loss:0.17955376214902646 \n",
      "Epoch:900 Loss:0.17955241419408438 \n",
      "Epoch:901 Loss:0.1795510770514772 \n",
      "Epoch:902 Loss:0.17954975063443887 \n",
      "Epoch:903 Loss:0.17954843485690133 \n",
      "Epoch:904 Loss:0.1795471296334876 \n",
      "Epoch:905 Loss:0.17954583487950618 \n",
      "Epoch:906 Loss:0.17954455051094603 \n",
      "Epoch:907 Loss:0.17954327644447107 \n",
      "Epoch:908 Loss:0.17954201259741442 \n",
      "Epoch:909 Loss:0.17954075888777352 \n",
      "Epoch:910 Loss:0.17953951523420372 \n",
      "Epoch:911 Loss:0.17953828155601484 \n",
      "Epoch:912 Loss:0.17953705777316367 \n",
      "Epoch:913 Loss:0.1795358438062503 \n",
      "Epoch:914 Loss:0.17953463957651267 \n",
      "Epoch:915 Loss:0.1795334450058211 \n",
      "Epoch:916 Loss:0.17953226001667344 \n",
      "Epoch:917 Loss:0.17953108453218997 \n",
      "Epoch:918 Loss:0.17952991847610802 \n",
      "Epoch:919 Loss:0.17952876177277813 \n",
      "Epoch:920 Loss:0.1795276143471573 \n",
      "Epoch:921 Loss:0.17952647612480624 \n",
      "Epoch:922 Loss:0.17952534703188255 \n",
      "Epoch:923 Loss:0.17952422699513748 \n",
      "Epoch:924 Loss:0.17952311594190992 \n",
      "Epoch:925 Loss:0.17952201380012192 \n",
      "Epoch:926 Loss:0.17952092049827575 \n",
      "Epoch:927 Loss:0.17951983596544607 \n",
      "Epoch:928 Loss:0.17951876013127818 \n",
      "Epoch:929 Loss:0.17951769292598155 \n",
      "Epoch:930 Loss:0.1795166342803267 \n",
      "Epoch:931 Loss:0.1795155841256394 \n",
      "Epoch:932 Loss:0.17951454239379686 \n",
      "Epoch:933 Loss:0.17951350901722377 \n",
      "Epoch:934 Loss:0.17951248392888655 \n",
      "Epoch:935 Loss:0.17951146706229068 \n",
      "Epoch:936 Loss:0.17951045835147506 \n",
      "Epoch:937 Loss:0.1795094577310078 \n",
      "Epoch:938 Loss:0.17950846513598276 \n",
      "Epoch:939 Loss:0.17950748050201487 \n",
      "Epoch:940 Loss:0.17950650376523575 \n",
      "Epoch:941 Loss:0.17950553486229018 \n",
      "Epoch:942 Loss:0.17950457373033055 \n",
      "Epoch:943 Loss:0.17950362030701503 \n",
      "Epoch:944 Loss:0.17950267453050137 \n",
      "Epoch:945 Loss:0.179501736339444 \n",
      "Epoch:946 Loss:0.17950080567298993 \n",
      "Epoch:947 Loss:0.17949988247077464 \n",
      "Epoch:948 Loss:0.17949896667291793 \n",
      "Epoch:949 Loss:0.1794980582200203 \n",
      "Epoch:950 Loss:0.17949715705315947 \n",
      "Epoch:951 Loss:0.17949626311388558 \n",
      "Epoch:952 Loss:0.1794953763442181 \n",
      "Epoch:953 Loss:0.17949449668664225 \n",
      "Epoch:954 Loss:0.17949362408410433 \n",
      "Epoch:955 Loss:0.17949275848000923 \n",
      "Epoch:956 Loss:0.17949189981821517 \n",
      "Epoch:957 Loss:0.17949104804303204 \n",
      "Epoch:958 Loss:0.17949020309921593 \n",
      "Epoch:959 Loss:0.1794893649319668 \n",
      "Epoch:960 Loss:0.179488533486924 \n",
      "Epoch:961 Loss:0.17948770871016365 \n",
      "Epoch:962 Loss:0.17948689054819456 \n",
      "Epoch:963 Loss:0.17948607894795438 \n",
      "Epoch:964 Loss:0.17948527385680713 \n",
      "Epoch:965 Loss:0.17948447522253907 \n",
      "Epoch:966 Loss:0.17948368299335576 \n",
      "Epoch:967 Loss:0.17948289711787793 \n",
      "Epoch:968 Loss:0.17948211754513918 \n",
      "Epoch:969 Loss:0.1794813442245817 \n",
      "Epoch:970 Loss:0.17948057710605367 \n",
      "Epoch:971 Loss:0.17947981613980593 \n",
      "Epoch:972 Loss:0.179479061276488 \n",
      "Epoch:973 Loss:0.17947831246714593 \n",
      "Epoch:974 Loss:0.17947756966321857 \n",
      "Epoch:975 Loss:0.17947683281653423 \n",
      "Epoch:976 Loss:0.17947610187930782 \n",
      "Epoch:977 Loss:0.17947537680413808 \n",
      "Epoch:978 Loss:0.17947465754400352 \n",
      "Epoch:979 Loss:0.17947394405226075 \n",
      "Epoch:980 Loss:0.17947323628264 \n",
      "Epoch:981 Loss:0.17947253418924305 \n",
      "Epoch:982 Loss:0.1794718377265401 \n",
      "Epoch:983 Loss:0.17947114684936646 \n",
      "Epoch:984 Loss:0.17947046151291993 \n",
      "Epoch:985 Loss:0.17946978167275804 \n",
      "Epoch:986 Loss:0.17946910728479465 \n",
      "Epoch:987 Loss:0.17946843830529755 \n",
      "Epoch:988 Loss:0.17946777469088512 \n",
      "Epoch:989 Loss:0.17946711639852445 \n",
      "Epoch:990 Loss:0.1794664633855273 \n",
      "Epoch:991 Loss:0.17946581560954813 \n",
      "Epoch:992 Loss:0.17946517302858137 \n",
      "Epoch:993 Loss:0.1794645356009586 \n",
      "Epoch:994 Loss:0.17946390328534514 \n",
      "Epoch:995 Loss:0.17946327604073847 \n",
      "Epoch:996 Loss:0.17946265382646495 \n",
      "Epoch:997 Loss:0.17946203660217716 \n",
      "Epoch:998 Loss:0.17946142432785156 \n",
      "Epoch:999 Loss:0.1794608169637858 \n",
      "Model Score 0.5991006876373717\n"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score 0.5507619904308948\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Predictions : [-0.35052149  0.62883125 -0.27445005 -0.57710096  0.43791706 -0.99863929\n",
      "  0.85121481 -1.77658805 -0.19946851 -0.69194372  0.80560467 -0.66925987\n",
      "  0.44211298 -0.04996854 -0.15121547 -0.24811524  2.45615275 -0.03947875\n",
      " -0.74913353  1.77851229 -0.6478866  -0.5603173  -0.19092543 -1.00244151\n",
      " -0.27958461 -0.92901298 -0.10490914  1.6026775  -0.57080709  1.77641433\n",
      "  0.80755138  0.04404588 -0.7527845  -1.00967403  1.6026775   0.41942913\n",
      " -0.35666412 -1.35070256 -0.59388463  0.82013913 -0.87501101  0.96030863\n",
      " -0.16629487  0.48866175  0.0230663  -0.55177422 -0.50826204 -1.13725578]\n",
      "Predictions : [ 1240.69150553  1358.54725042  1249.84597596  1213.42483053  1335.57255205\n",
      "  1162.69671997  1385.30898699  1069.07801951  1258.86928886  1199.60460259\n",
      "  1379.82024307  1202.3343864   1336.07749047  1276.86018174  1264.67608075\n",
      "  1253.01511942  1578.44793487  1278.1225278   1192.72235507  1496.9003791\n",
      "  1204.90645606  1215.44458424  1259.89736694  1162.23915908  1249.22808123\n",
      "  1171.07558153  1270.24860467  1475.74034275  1214.18223817  1496.64790988\n",
      "  1380.05451105  1288.17391879  1192.28299541  1161.36879514  1475.74034275\n",
      "  1333.34770666  1239.95229912  1120.32926973  1211.40507683  1381.56932633\n",
      "  1177.5742023   1398.43738606  1262.86141873  1341.67919069  1285.64922666\n",
      "  1216.47266232  1221.70893702  1146.01555068]\n",
      "     Ones    Gender  Age Range  Head Size(cm^3)\n",
      "115     1 -0.874879   0.928702        -0.369575\n",
      "15      1 -0.874879  -1.072228         0.662562\n",
      "211     1  1.138192   0.928702        -0.147816\n",
      "126     1 -0.874879   0.928702        -0.665254\n",
      "6       1 -0.874879  -1.072228         0.413426\n",
      "170     1  1.138192  -1.072228        -1.338744\n",
      "9       1 -0.874879  -1.072228         0.952765\n",
      "221     1  1.138192   0.928702        -2.108056\n",
      "112     1 -0.874879   0.928702        -0.172456\n",
      "220     1  1.138192   0.928702        -0.692631\n",
      "182     1  1.138192  -1.072228         1.015734\n",
      "137     1  1.138192  -1.072228        -0.908915\n",
      "30      1 -0.874879  -1.072228         0.418901\n",
      "193     1  1.138192   0.928702         0.145125\n",
      "113     1 -0.874879   0.928702        -0.109488\n",
      "55      1 -0.874879  -1.072228        -0.481824\n",
      "24      1 -0.874879  -1.072228         3.047156\n",
      "205     1  1.138192   0.928702         0.158813\n",
      "86      1 -0.874879   0.928702        -0.889751\n",
      "19      1 -0.874879  -1.072228         2.162858\n",
      "206     1  1.138192   0.928702        -0.635138\n",
      "120     1 -0.874879   0.928702        -0.643352\n",
      "141     1  1.138192  -1.072228        -0.284704\n",
      "234     1  1.138192   0.928702        -1.097821\n",
      "10      1 -0.874879  -1.072228        -0.522890\n",
      "218     1  1.138192   0.928702        -1.001999\n",
      "172     1  1.138192  -1.072228        -0.172456\n",
      "109     1 -0.874879   0.928702         2.179284\n",
      "75      1 -0.874879   0.928702        -0.657041\n",
      "25      1 -0.874879  -1.072228         2.160120\n",
      "124     1 -0.874879   0.928702         1.141671\n",
      "185     1  1.138192  -1.072228         0.021925\n",
      "235     1  1.138192   0.928702        -0.772027\n",
      "18      1 -0.874879  -1.072228        -1.475632\n",
      "68      1 -0.874879   0.928702         2.179284\n",
      "60      1 -0.874879   0.928702         0.635185\n",
      "148     1  1.138192  -1.072228        -0.500988\n",
      "204     1  1.138192   0.928702        -1.552290\n",
      "114     1 -0.874879   0.928702        -0.687156\n",
      "73      1 -0.874879   0.928702         1.158098\n",
      "82      1 -0.874879   0.928702        -1.054016\n",
      "45      1 -0.874879  -1.072228         1.095129\n",
      "16      1 -0.874879  -1.072228        -0.375051\n",
      "93      1 -0.874879   0.928702         0.725531\n",
      "186     1  1.138192  -1.072228        -0.005452\n",
      "167     1  1.138192  -1.072228        -0.755600\n",
      "38      1 -0.874879  -1.072228        -0.821306\n",
      "127     1 -0.874879   0.928702        -1.396237\n"
     ]
    }
   ],
   "source": [
    "model.predictTest(X_test,mean['Brain Weight(grams)'], std['Brain Weight(grams)'])\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age Range</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Head Size(cm^3)</th>\n",
       "      <td>4512</td>\n",
       "      <td>3738</td>\n",
       "      <td>4261</td>\n",
       "      <td>3777</td>\n",
       "      <td>4177</td>\n",
       "      <td>3585</td>\n",
       "      <td>3785</td>\n",
       "      <td>3559</td>\n",
       "      <td>3613</td>\n",
       "      <td>3982</td>\n",
       "      <td>...</td>\n",
       "      <td>4204</td>\n",
       "      <td>3735</td>\n",
       "      <td>3218</td>\n",
       "      <td>3685</td>\n",
       "      <td>3704</td>\n",
       "      <td>3214</td>\n",
       "      <td>3394</td>\n",
       "      <td>3233</td>\n",
       "      <td>3352</td>\n",
       "      <td>3391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0     1     2     3     4     5     6     7     8     9    \\\n",
       "Gender              1     1     1     1     1     1     1     1     1     1   \n",
       "Age Range           1     1     1     1     1     1     1     1     1     1   \n",
       "Head Size(cm^3)  4512  3738  4261  3777  4177  3585  3785  3559  3613  3982   \n",
       "\n",
       "                 ...    227   228   229   230   231   232   233   234   235  \\\n",
       "Gender           ...      2     2     2     2     2     2     2     2     2   \n",
       "Age Range        ...      2     2     2     2     2     2     2     2     2   \n",
       "Head Size(cm^3)  ...   4204  3735  3218  3685  3704  3214  3394  3233  3352   \n",
       "\n",
       "                  236  \n",
       "Gender              2  \n",
       "Age Range           2  \n",
       "Head Size(cm^3)  3391  \n",
       "\n",
       "[3 rows x 237 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
